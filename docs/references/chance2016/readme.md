2
https://scholar.google.com/scholar?um=1&ie=UTF-8&lr&cites=12189513691706830157
Thu Feb 21 19:58:56 GMT 2019


```
@INPROCEEDINGS{8172315, 
author={G. {Chance} and P. {Caleb-Solly} and A. {Jevtić} and S. {Dogramadzi}}, 
booktitle={2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)}, 
title={What's “up”? — Resolving interaction ambiguity through non-visual cues for a robotic dressing assistant}, 
year={2017}, 
volume={}, 
number={}, 
pages={284-291}, 
doi={10.1109/ROMAN.2017.8172315}, 
ISSN={1944-9437}, 
month={Aug},}

```

```
keywords={computer vision;end effectors;force feedback;haptic interfaces;human computer interaction;human-robot interaction;image motion analysis;medical robotics;mobile robots;position control;robot vision;service robots;verbal force feedback analysis;ambiguous command;deictic words;reliable HRI;safe HRI;assisted-dressing task;researcher mimicking robot behaviour;human-human dressing experiment;proprioceptive force feedback;human-robot interaction;user privacy;technical complexity;vision systems;intuitive interaction;daily living;robotic dressing assistant;nonvisual cues;interaction ambiguity;end-effector position;nonvisual means;predictive model;end-effector height;end effector choice;Clothing;Predictive models;Robot sensing systems;Speech;End effectors}, 
```

